{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c4abd0f8-2022-46bb-aeac-2be34c8ddac6",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### [User Input Required] Read Parquet Source with Autoloader.\n",
    "\n",
    "__Common data loading patterns__: https://docs.databricks.com/en/ingestion/auto-loader/patterns.html\n",
    "\n",
    "__Autoloader Options for Parquet__: https://docs.databricks.com/en/ingestion/auto-loader/options.html#parquet-options\n",
    "\n",
    "__Common Autoloader Options__: https://docs.databricks.com/en/ingestion/auto-loader/options.html#common-auto-loader-options\n",
    "\n",
    "__Schema Evolution Modes__: https://docs.databricks.com/en/ingestion/auto-loader/schema.html#how-does-auto-loader-schema-evolution-work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f95a4641-7e41-4316-9394-8f913d0e4644",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls dbfs:/databricks-datasets/airlines\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "45c5a37a-0c0e-43b3-8212-605a744edd0b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import dlt\n",
    "\n",
    "# [User Input Required] Set the input/output locations, metadata\n",
    "input_location = \"dbfs:/databricks-datasets/airlines/\"\n",
    "output_table = \"bronze_nyctaxi_tripdata_yellow\"\n",
    "output_table_comments = \"Bronze data for yellow NYC taxi trips\"\n",
    "\n",
    "# [User Input Required] Configure schema evolution and rescue data.\n",
    "schema_evolution_mode = \"addNewColumns\"\n",
    "rescue_data_column_name = \"_rescued_data\"\n",
    "\n",
    "\n",
    "@dlt.table(name=f\"{output_table}_autoloader\", temporary = True)\n",
    "def tmp():\n",
    "  # [User Input Required] Configure Autoloader settings \n",
    "  df = (\n",
    "    spark.readStream.format(\"cloudFiles\")\n",
    "    .option(\"cloudFiles.format\", \"parquet\")\n",
    "    .option(\"cloudFiles.mergeSchema\", \"true\")\n",
    "    .option(\"cloudFiles.schemaEvolutionMode\", schema_evolution_mode)\n",
    "    .option(\"cloudFiles.rescuedDataColumn\", rescue_data_column_name)\n",
    "    # Add additional autoloader settings below\n",
    "    .load(input_location)\n",
    "  )\n",
    "  return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ba190cef-2ef3-4a4e-8b25-6a58adcd2821",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "### [Optional User Input Required] Transformations + Write Data to Unity Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "099c2d16-b768-44d8-b449-9eb0b4b5861e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@dlt.table(name=output_table, comment = output_table_comments)\n",
    "def t():\n",
    "  # Read data from temporary autoloader table\n",
    "  df = spark.readStream.table(f\"live.{output_table}_autoloader\")\n",
    "\n",
    "  # [User Input Required] Optional Transformations Below\n",
    "\n",
    "  return df"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "python_parquet_ingestion_template",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
